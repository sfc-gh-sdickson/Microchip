{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Microchip ML Models - Model Registry\n",
        "\n",
        "This notebook trains ML models for the Microchip Intelligence Agent:\n",
        "- **Revenue Forecasting** - Predict future monthly revenue\n",
        "- **Customer Churn Prediction** - Classify customers at risk of churning\n",
        "- **Design Win Conversion** - Predict which designs will go to production\n",
        "\n",
        "All models are registered to Snowflake Model Registry and can be added as tools to the Intelligence Agent.\n",
        "\n",
        "## Before You Begin\n",
        "\n",
        "**Add these packages** in the Packages dropdown (upper right):\n",
        "- `snowflake-ml-python`\n",
        "- `scikit-learn`\n",
        "- `xgboost`\n",
        "- `matplotlib`\n",
        "\n",
        "**Database:** MICROCHIP_INTELLIGENCE_TM  \n",
        "**Schema:** ANALYTICS_TM  \n",
        "**Warehouse:** MICROCHIP_WH_TM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Python packages\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "from snowflake.snowpark import Window\n",
        "\n",
        "# Import Snowpark ML\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to Snowflake\n",
        "\n",
        "Get active session and set context to Microchip database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.use_database('MICROCHIP_INTELLIGENCE_TM')\n",
        "session.use_schema('ANALYTICS_TM')\n",
        "session.use_warehouse('MICROCHIP_WH_TM')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n",
        "print(f\"   Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"   Database.Schema: {session.get_fully_qualified_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 1: Revenue Forecasting\n",
        "\n",
        "Predict future monthly revenue using historical order data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Revenue Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get monthly revenue data with features\n",
        "revenue_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    DATE_TRUNC('month', order_date)::DATE AS order_month,\n",
        "    MONTH(order_date) AS month_num,\n",
        "    YEAR(order_date) AS year_num,\n",
        "    SUM(order_amount)::FLOAT AS total_revenue,\n",
        "    COUNT(DISTINCT order_id)::FLOAT AS order_count,\n",
        "    COUNT(DISTINCT customer_id)::FLOAT AS customer_count,\n",
        "    AVG(order_amount)::FLOAT AS avg_order_value\n",
        "FROM RAW_TM.ORDERS_TM\n",
        "WHERE order_date >= DATEADD('month', -30, CURRENT_DATE())\n",
        "  AND payment_status = 'COMPLETED'\n",
        "GROUP BY DATE_TRUNC('month', order_date), MONTH(order_date), YEAR(order_date)\n",
        "ORDER BY order_month\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Revenue data: {revenue_df.count()} months\")\n",
        "revenue_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Data and Train Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (last 6 months for testing)\n",
        "train_revenue = revenue_df.filter(F.col(\"ORDER_MONTH\") < F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "test_revenue = revenue_df.filter(F.col(\"ORDER_MONTH\") >= F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "\n",
        "# Drop ORDER_MONTH (DATE type not supported in pipeline)\n",
        "train_revenue = train_revenue.drop(\"ORDER_MONTH\")\n",
        "test_revenue = test_revenue.drop(\"ORDER_MONTH\")\n",
        "\n",
        "# Create pipeline\n",
        "revenue_pipeline = Pipeline([\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"MONTH_NUM\", \"ORDER_COUNT\", \"CUSTOMER_COUNT\", \"AVG_ORDER_VALUE\"],\n",
        "        output_cols=[\"MONTH_NUM_SCALED\", \"ORDER_COUNT_SCALED\", \"CUSTOMER_COUNT_SCALED\", \"AVG_ORDER_VALUE_SCALED\"]\n",
        "    )),\n",
        "    (\"LinearRegression\", LinearRegression(\n",
        "        label_cols=[\"TOTAL_REVENUE\"],\n",
        "        output_cols=[\"PREDICTED_REVENUE\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "revenue_pipeline.fit(train_revenue)\n",
        "print(\"✅ Revenue forecasting model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "test_predictions = revenue_pipeline.predict(test_revenue)\n",
        "\n",
        "# Calculate metrics\n",
        "mae = mean_absolute_error(df=test_predictions, y_true_col_names=\"TOTAL_REVENUE\", y_pred_col_names=\"PREDICTED_REVENUE\")\n",
        "mse = mean_squared_error(df=test_predictions, y_true_col_names=\"TOTAL_REVENUE\", y_pred_col_names=\"PREDICTED_REVENUE\")\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "metrics = {\"mae\": round(mae, 2), \"rmse\": round(rmse, 2)}\n",
        "print(f\"Model metrics: {metrics}\")\n",
        "\n",
        "# Register model (use different name to avoid conflict with ML Functions)\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=revenue_pipeline,\n",
        "    model_name=\"REVENUE_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts monthly revenue based on historical order patterns using Linear Regression\",\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Revenue model registered to Model Registry as REVENUE_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 2: Customer Churn Prediction\n",
        "\n",
        "Classify customers as likely to churn or not based on behavior patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Churn Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get customer features for churn prediction\n",
        "churn_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    c.customer_id,\n",
        "    c.customer_segment,\n",
        "    c.industry_vertical,\n",
        "    c.lifetime_value::FLOAT AS lifetime_value,\n",
        "    c.credit_risk_score::FLOAT AS credit_risk_score,\n",
        "    -- Recent orders (last 3 months)\n",
        "    COUNT(DISTINCT CASE WHEN o.order_date >= DATEADD('month', -3, CURRENT_DATE()) \n",
        "                   THEN o.order_id END)::FLOAT AS recent_orders,\n",
        "    -- Historical average\n",
        "    (COUNT(DISTINCT CASE WHEN o.order_date < DATEADD('month', -3, CURRENT_DATE()) \n",
        "                    THEN o.order_id END) / 9.0)::FLOAT AS historical_avg_orders,\n",
        "    -- Support satisfaction\n",
        "    AVG(CASE WHEN st.created_date >= DATEADD('month', -6, CURRENT_DATE()) \n",
        "        THEN st.customer_satisfaction_score::FLOAT END) AS avg_csat,\n",
        "    -- Quality issues\n",
        "    COUNT(DISTINCT qi.quality_issue_id)::FLOAT AS quality_issue_count,\n",
        "    -- Design wins\n",
        "    COUNT(DISTINCT CASE WHEN dw.design_win_date >= DATEADD('month', -12, CURRENT_DATE()) \n",
        "                   THEN dw.design_win_id END)::FLOAT AS recent_design_wins,\n",
        "    -- Target: Is churned\n",
        "    (c.customer_status = 'CHURNED' \n",
        "     OR (COUNT(DISTINCT CASE WHEN o.order_date >= DATEADD('month', -3, CURRENT_DATE()) \n",
        "                        THEN o.order_id END) = 0 \n",
        "         AND COUNT(DISTINCT CASE WHEN o.order_date < DATEADD('month', -3, CURRENT_DATE()) \n",
        "                            THEN o.order_id END) > 5))::BOOLEAN AS is_churned\n",
        "FROM RAW_TM.CUSTOMERS_TM c\n",
        "LEFT JOIN RAW_TM.ORDERS_TM o ON c.customer_id = o.customer_id\n",
        "LEFT JOIN RAW_TM.SUPPORT_TICKETS_TM st ON c.customer_id = st.customer_id\n",
        "LEFT JOIN RAW_TM.QUALITY_ISSUES_TM qi ON c.customer_id = qi.customer_id\n",
        "LEFT JOIN RAW_TM.DESIGN_WINS_TM dw ON c.customer_id = dw.customer_id\n",
        "GROUP BY c.customer_id, c.customer_segment, c.industry_vertical, c.lifetime_value, c.credit_risk_score, c.customer_status\n",
        "HAVING COUNT(DISTINCT o.order_id) > 10\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Churn data: {churn_df.count()} customers\")\n",
        "churn_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Churn Classification Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_churn, test_churn = churn_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop CUSTOMER_ID and drop original string columns after they'll be encoded\n",
        "train_churn = train_churn.drop(\"CUSTOMER_ID\")\n",
        "test_churn = test_churn.drop(\"CUSTOMER_ID\")\n",
        "\n",
        "# Create pipeline with preprocessing and classification\n",
        "churn_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"CUSTOMER_SEGMENT\", \"INDUSTRY_VERTICAL\"],\n",
        "        output_cols=[\"CUSTOMER_SEGMENT_ENCODED\", \"INDUSTRY_VERTICAL_ENCODED\"],\n",
        "        drop_input_cols=True,  # Drop original string columns after encoding\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_CHURNED\"],\n",
        "        output_cols=[\"CHURN_PREDICTION\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "churn_pipeline.fit(train_churn)\n",
        "print(\"✅ Churn classification model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Churn Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "churn_predictions = churn_pipeline.predict(test_churn)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(df=churn_predictions, y_true_col_names=\"IS_CHURNED\", y_pred_col_names=\"CHURN_PREDICTION\")\n",
        "# Note: ROC AUC might need probability scores - using accuracy for now\n",
        "churn_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Churn model metrics: {churn_metrics}\")\n",
        "\n",
        "# Register model (use different name to avoid conflict)\n",
        "reg.log_model(\n",
        "    model=churn_pipeline,\n",
        "    model_name=\"CHURN_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts customer churn probability using Random Forest based on behavior patterns\",\n",
        "    metrics=churn_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Churn model registered to Model Registry as CHURN_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 3: Design Win Conversion Prediction\n",
        "\n",
        "Predict which design wins are likely to convert to production orders.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Design Win Conversion Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get design win features\n",
        "conversion_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    dw.design_win_id,\n",
        "    p.product_family,\n",
        "    c.customer_segment,\n",
        "    c.industry_vertical,\n",
        "    dw.estimated_annual_volume::FLOAT AS estimated_volume,\n",
        "    dw.competitive_displacement::BOOLEAN AS is_competitive_win,\n",
        "    -- Has this design gone to production?\n",
        "    (EXISTS (SELECT 1 FROM RAW_TM.PRODUCTION_ORDERS_TM po \n",
        "             WHERE po.design_win_id = dw.design_win_id))::BOOLEAN AS converted_to_production\n",
        "FROM RAW_TM.DESIGN_WINS_TM dw\n",
        "JOIN RAW_TM.PRODUCT_CATALOG_TM p ON dw.product_id = p.product_id\n",
        "JOIN RAW_TM.CUSTOMERS_TM c ON dw.customer_id = c.customer_id\n",
        "WHERE dw.design_win_date >= DATEADD('month', -24, CURRENT_DATE())\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Design win data: {conversion_df.count()} design wins\")\n",
        "conversion_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "train_conversion, test_conversion = conversion_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop DESIGN_WIN_ID (VARCHAR not supported as feature)\n",
        "train_conversion = train_conversion.drop(\"DESIGN_WIN_ID\")\n",
        "test_conversion = test_conversion.drop(\"DESIGN_WIN_ID\")\n",
        "\n",
        "# Create pipeline\n",
        "conversion_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"PRODUCT_FAMILY\", \"CUSTOMER_SEGMENT\", \"INDUSTRY_VERTICAL\"],\n",
        "        output_cols=[\"PRODUCT_FAMILY_ENC\", \"CUSTOMER_SEGMENT_ENC\", \"INDUSTRY_VERTICAL_ENC\"],\n",
        "        drop_input_cols=True,  # Drop original string columns after encoding\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", LogisticRegression(\n",
        "        label_cols=[\"CONVERTED_TO_PRODUCTION\"],\n",
        "        output_cols=[\"CONVERSION_PREDICTION\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "conversion_pipeline.fit(train_conversion)\n",
        "print(\"✅ Design win conversion model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "conversion_predictions = conversion_pipeline.predict(test_conversion)\n",
        "\n",
        "# Calculate accuracy\n",
        "conv_accuracy = accuracy_score(df=conversion_predictions, \n",
        "                                y_true_col_names=\"CONVERTED_TO_PRODUCTION\",\n",
        "                                y_pred_col_names=\"CONVERSION_PREDICTION\")\n",
        "conv_metrics = {\"accuracy\": round(conv_accuracy, 4)}\n",
        "print(f\"Conversion model metrics: {conv_metrics}\")\n",
        "\n",
        "# Register model (use different name to avoid conflict)\n",
        "reg.log_model(\n",
        "    model=conversion_pipeline,\n",
        "    model_name=\"CONVERSION_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts design win to production conversion using Logistic Regression\",\n",
        "    metrics=conv_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Conversion model registered to Model Registry as CONVERSION_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Verify Models in Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show all models in the registry\n",
        "print(\"Models in registry:\")\n",
        "reg.show_models()\n",
        "\n",
        "# Show versions for revenue model\n",
        "print(\"\\nRevenue model versions:\")\n",
        "reg.get_model(\"REVENUE_PREDICTOR\").show_versions()\n",
        "\n",
        "# Show versions for churn model  \n",
        "print(\"\\nChurn model versions:\")\n",
        "reg.get_model(\"CHURN_PREDICTOR\").show_versions()\n",
        "\n",
        "# Show versions for conversion model\n",
        "print(\"\\nConversion model versions:\")\n",
        "reg.get_model(\"CONVERSION_PREDICTOR\").show_versions()\n",
        "\n",
        "print(\"\\n✅ All models registered and ready to add to Intelligence Agent\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Test Model Inference\n",
        "\n",
        "Test calling each model to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test revenue forecast on recent data\n",
        "revenue_model = reg.get_model(\"REVENUE_PREDICTOR\").default\n",
        "recent_revenue = revenue_df.limit(3).drop(\"ORDER_MONTH\")\n",
        "revenue_preds = revenue_model.run(recent_revenue, function_name=\"predict\")\n",
        "print(\"Revenue predictions:\")\n",
        "revenue_preds.select(\"TOTAL_REVENUE\", \"PREDICTED_REVENUE\").show()\n",
        "\n",
        "# Test churn prediction on sample customers\n",
        "churn_model = reg.get_model(\"CHURN_PREDICTOR\").default\n",
        "sample_customers = churn_df.limit(5).drop(\"CUSTOMER_ID\")\n",
        "churn_preds = churn_model.run(sample_customers, function_name=\"predict\")\n",
        "print(\"\\nChurn predictions:\")\n",
        "churn_preds.select(\"IS_CHURNED\", \"CHURN_PREDICTION\").show()\n",
        "\n",
        "# Test conversion prediction\n",
        "conversion_model = reg.get_model(\"CONVERSION_PREDICTOR\").default\n",
        "sample_designs = conversion_df.limit(5).drop(\"DESIGN_WIN_ID\")\n",
        "conversion_preds = conversion_model.run(sample_designs, function_name=\"predict\")\n",
        "print(\"\\nConversion predictions:\")\n",
        "conversion_preds.select(\"CONVERTED_TO_PRODUCTION\", \"CONVERSION_PREDICTION\").show()\n",
        "\n",
        "print(\"\\n✅ All models tested successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Next Steps\n",
        "\n",
        "## Add Models to Intelligence Agent\n",
        "\n",
        "1. In Snowsight → AI & ML → Agents → MICROCHIP_INTELLIGENCE_AGENT\n",
        "2. Go to Tools → + Add → Model\n",
        "3. Add each registered model:\n",
        "   - **REVENUE_PREDICTOR**\n",
        "   - **CHURN_PREDICTOR**\n",
        "   - **CONVERSION_PREDICTOR**\n",
        "\n",
        "## Example Questions for Agent\n",
        "\n",
        "- \"Forecast revenue for the next quarter using the revenue predictor\"\n",
        "- \"Which customers are predicted to churn according to the churn predictor?\"\n",
        "- \"Show me design wins with high conversion probability using the conversion predictor\"\n",
        "\n",
        "The models will now be available as tools your agent can use!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
